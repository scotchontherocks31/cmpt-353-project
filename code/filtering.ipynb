{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_json(\"../amenities-vancouver.json\", lines=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# value_counts to dataframe from https://stackoverflow.com/a/53869812\n",
    "d = pd.DataFrame(df[\"amenity\"].value_counts(ascending=True))\n",
    "amenity_count = d.reset_index()\n",
    "amenity_count.columns = [\"amenity\", \"count\"]\n",
    "amenity_count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# maybe it is more interesting to ask for amenities that are more common on the map\n",
    "# for example if there is only 1 luggage_locker on the entire map, \n",
    "# then when I request for loggage_locker in area A, it will either return no results or the result near the luggage_locker. This isn't very interesting.\n",
    "df = df.merge(amenity_count, on=\"amenity\")\n",
    "df = df[df[\"count\"] > 30]\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We see that there are many occurances of certain amenities, and these could be interesting inputs for us to search for on the map\n",
    "df[\"amenity\"].value_counts(ascending=False)[:20]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# flattening the tags to extract useful information for training our data\n",
    "df[\"city\"] = pd.json_normalize(df[\"tags\"])[\"addr:city\"]\n",
    "df[\"postcode\"] = pd.json_normalize(df[\"tags\"])[\"addr:postcode\"]\n",
    "df[\"street\"] = pd.json_normalize(df[\"tags\"])[\"addr:street\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We can see that we have some data points that are misspelled or similar\n",
    "# We can either remove these data points or fix them up and not discard them\n",
    "df[\"city\"].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Manually replace them with the correct ones\n",
    "# For the simplicity for the training model, we don't want cities with too little datapoints since this will just be \"discarded\" during training\n",
    "# therefore, we group them with the closest municipal/city\n",
    "df = df.replace([\"vancouver\",\"Vancovuer\", \"Vancouver, BC, Canada\"], \"Vancouver\")\n",
    "df = df.replace([\"North Vancouver City\", \"District of North Vancouver\"], \"North Vancouver\")\n",
    "df = df.replace(\"Abbosford\", \"Abbotsford\")\n",
    "df = df.replace(\"Langley\", \"Langley\")\n",
    "df = df.replace([\"Hatzic\", \"Lake Errock\"], \"Mission\")\n",
    "df = df.replace([\"Township of Langley\", \"City of Langley/Township of Langley Border\", \"Langley Township\", \"Fort Langley\", \"Aldergrove\"], \"Langley\")\n",
    "\n",
    "df.to_json(\"../filtered-vancouver-all.json\", orient=\"records\", lines=True)\n",
    "df[\"city\"].value_counts() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create json with features that seem useful \n",
    "training_df = df[df[\"city\"].notna()]\n",
    "training_df = training_df[[\"lon\", \"lat\", \"amenity\", \"name\", \"city\", \"postcode\", \"street\"]]\n",
    "training_df.to_json(\"../filtered-vancouver-training.json\", orient=\"records\", lines=True)\n",
    "training_df\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create json with testing data \n",
    "training_df = df[df[\"city\"].notna() == False]\n",
    "training_df = training_df[[\"lon\", \"lat\", \"amenity\", \"name\", \"city\", \"postcode\", \"street\"]]\n",
    "\n",
    "training_df.to_json(\"../filtered-vancouver-testing.json\", orient=\"records\", lines=True)\n",
    "training_df\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# perhaps we have too little data points for each region to make the training work\n",
    "# since we cannot just get more data points, maybe we need to decrease the amount of regions\n",
    "# and combine regions so that each region has more data points for the training \n",
    "training_df_small = df[df[\"city\"].notna()]\n",
    "training_df_small = training_df_small[[\"lon\", \"lat\", \"amenity\", \"name\", \"city\", \"postcode\", \"street\"]]\n",
    "training_df_small\n",
    "training_df_small = training_df_small.replace([\"North Vancouver\", \"West Vancouver\"], \"Vancouver\")\n",
    "training_df_small = training_df_small.replace(\"Port Coquitlam\", \"Coquitlam\")\n",
    "training_df_small = training_df_small.replace(\"Pitt Meadows\", \"Maple Ridge\")\n",
    "training_df_small = training_df_small.replace([\"Langley\", \"Delta\"], \"Surrey\")\n",
    "training_df_small = training_df_small.replace(\"New Westminster\", \"Burnaby\")\n",
    "training_df_small = training_df_small[\n",
    "    (training_df_small[\"city\"] == \"Vancouver\") | \n",
    "    (training_df_small[\"city\"] == \"Surrey\") | \n",
    "    (training_df_small[\"city\"] == \"Burnaby\") |  \n",
    "    (training_df_small[\"city\"] == \"Richmond\") |  \n",
    "    (training_df_small[\"city\"] == \"Coquitlam\")\n",
    "]\n",
    "training_df_small.to_json(\"../filtered-vancouver-training-6-category.json\", orient=\"records\", lines=True)\n",
    "training_df_small[\"city\"].value_counts() \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# maybe it is also useful to sort by amenity occurances and discard the ones that do not occur that often\n",
    "training_df_small_remove_amenity = training_df_small.copy()\n",
    "d = training_df_small_remove_amenity[\"amenity\"].value_counts()\n",
    "amenity_count = d.reset_index()\n",
    "amenity_count.columns = [\"amenity\", \"count\"]\n",
    "training_df_small_remove_amenity = training_df_small_remove_amenity.merge(amenity_count, on=\"amenity\")\n",
    "training_df_small_remove_amenity = training_df_small_remove_amenity[training_df_small_remove_amenity[\"count\"] >= 10]\n",
    "training_df_small_remove_amenity.drop(\"count\", axis=1)\n",
    "\n",
    "training_df_small_remove_amenity.to_json(\"../filtered-vancouver-training-amenity-removed.json\", orient=\"records\", lines=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}